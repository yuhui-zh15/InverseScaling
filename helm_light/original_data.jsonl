{
  "adapter_spec": {
    "method": "multiple_choice_joint",
    "global_prefix": "",
    "instructions": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n",
    "input_prefix": "Question: ",
    "input_suffix": "\n",
    "reference_prefix": "A. ",
    "reference_suffix": "\n",
    "output_prefix": "Answer: ",
    "output_suffix": "\n",
    "instance_prefix": "\n",
    "substitutions": [],
    "max_train_instances": 5,
    "max_eval_instances": 100,
    "num_outputs": 1,
    "num_train_trials": 1,
    "model": "ai21/j1-large",
    "temperature": 0.0,
    "max_tokens": 200,
    "stop_sequences": [
      "\n\n"
    ]
  },
  "request_states": [
    {
      "instance": {
        "input": "Eden Roc Renaissance Hotel Miami Beach is not a ___ ?",
        "references": [
          {
            "output": "hotel",
            "tags": []
          },
          {
            "output": "download",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id638"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "hotel",
        "answer is B.": "download"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Eden Roc Renaissance Hotel Miami Beach is not a ___ ?\nA. hotel\nB. download\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.1315460852347314,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.040875740349292755,
                "top_logprobs": {
                  " The answer is": -0.040875740349292755
                }
              },
              {
                "text": " B.",
                "logprob": -1.0375573635101318,
                "top_logprobs": {
                  " B.": -1.0375573635101318
                }
              },
              {
                "text": "",
                "logprob": -0.04548107460141182,
                "top_logprobs": {
                  "\n": -0.04548107460141182
                }
              },
              {
                "text": "",
                "logprob": -0.007631906773895025,
                "top_logprobs": {
                  "\n": -0.007631906773895025
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.4064033031463623,
        "request_datetime": 1672432880
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "The Betty Hutton Show was not originally aired on ___ ?",
        "references": [
          {
            "output": "youtube",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "cbs",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id545"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "youtube",
        "answer is B.": "cbs"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: The Betty Hutton Show was not originally aired on ___ ?\nA. youtube\nB. cbs\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is A.",
            "logprob": -1.10063132410869,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.022705812007188797,
                "top_logprobs": {
                  " The answer is": -0.022705812007188797
                }
              },
              {
                "text": " A.",
                "logprob": -1.0012515783309937,
                "top_logprobs": {
                  " A.": -1.0012515783309937
                }
              },
              {
                "text": "",
                "logprob": -0.07214625924825668,
                "top_logprobs": {
                  "\n": -0.07214625924825668
                }
              },
              {
                "text": "",
                "logprob": -0.004527674522250891,
                "top_logprobs": {
                  "\n": -0.004527674522250891
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.46923255920410156,
        "request_datetime": 1672432880
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Hot 8 Brass Band does not play ___ music ?",
        "references": [
          {
            "output": "jazz",
            "tags": []
          },
          {
            "output": "friedrich",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id688"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "jazz",
        "answer is B.": "friedrich"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Hot 8 Brass Band does not play ___ music ?\nA. jazz\nB. friedrich\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.0563710164278746,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.05435575544834137,
                "top_logprobs": {
                  " The answer is": -0.05435575544834137
                }
              },
              {
                "text": " B.",
                "logprob": -0.955388069152832,
                "top_logprobs": {
                  " B.": -0.955388069152832
                }
              },
              {
                "text": "",
                "logprob": -0.03568273410201073,
                "top_logprobs": {
                  "\n": -0.03568273410201073
                }
              },
              {
                "text": "",
                "logprob": -0.010944457724690437,
                "top_logprobs": {
                  "\n": -0.010944457724690437
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3419039249420166,
        "request_datetime": 1672432880
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Crying is not part of ___?",
        "references": [
          {
            "output": "life",
            "tags": []
          },
          {
            "output": "love",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id14"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "life",
        "answer is B.": "love"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Crying is not part of ___?\nA. life\nB. love\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is A.",
            "logprob": -0.8740215352736413,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04323934391140938,
                "top_logprobs": {
                  " The answer is": -0.04323934391140938
                }
              },
              {
                "text": " A.",
                "logprob": -0.7695417404174805,
                "top_logprobs": {
                  " A.": -0.7695417404174805
                }
              },
              {
                "text": "",
                "logprob": -0.05501319468021393,
                "top_logprobs": {
                  "\n": -0.05501319468021393
                }
              },
              {
                "text": "",
                "logprob": -0.006227256264537573,
                "top_logprobs": {
                  "\n": -0.006227256264537573
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3399841785430908,
        "request_datetime": 1672432880
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Melbourne International Film Festival is not located in ___ ?",
        "references": [
          {
            "output": "april",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "melbourne",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id261"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "april",
        "answer is B.": "melbourne"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Melbourne International Film Festival is not located in ___ ?\nA. april\nB. melbourne\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.0983520140871406,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.07550555467605591,
                "top_logprobs": {
                  " The answer is": -0.07550555467605591
                }
              },
              {
                "text": " B.",
                "logprob": -0.9559732675552368,
                "top_logprobs": {
                  " B.": -0.9559732675552368
                }
              },
              {
                "text": "",
                "logprob": -0.055735260248184204,
                "top_logprobs": {
                  "\n": -0.055735260248184204
                }
              },
              {
                "text": "",
                "logprob": -0.011137931607663631,
                "top_logprobs": {
                  "\n": -0.011137931607663631
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.34627580642700195,
        "request_datetime": 1672432880
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Mitsubishi G4M is not developed by ___ ?",
        "references": [
          {
            "output": "mitsubishi",
            "tags": []
          },
          {
            "output": "vinci",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id240"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "mitsubishi",
        "answer is B.": "vinci"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Mitsubishi G4M is not developed by ___ ?\nA. mitsubishi\nB. vinci\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.0634247115813196,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.07314872741699219,
                "top_logprobs": {
                  " The answer is": -0.07314872741699219
                }
              },
              {
                "text": " B.",
                "logprob": -0.9251460433006287,
                "top_logprobs": {
                  " B.": -0.9251460433006287
                }
              },
              {
                "text": "",
                "logprob": -0.057536009699106216,
                "top_logprobs": {
                  "\n": -0.057536009699106216
                }
              },
              {
                "text": "",
                "logprob": -0.0075939311645925045,
                "top_logprobs": {
                  "\n": -0.0075939311645925045
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.376190185546875,
        "request_datetime": 1672432881
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "A man grows flowers in the winter using his greenhouse. The flowers blossom there, despite the cold, freezing weather and lack of sunshine, not because",
        "references": [
          {
            "output": "they are regularly chilled",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "they are carefully protected",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id943"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "they are regularly chilled",
        "answer is B.": "they are carefully protected"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: A man grows flowers in the winter using his greenhouse. The flowers blossom there, despite the cold, freezing weather and lack of sunshine, not because\nA. they are regularly chilled\nB. they are carefully protected\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.5890901503153145,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.01756012998521328,
                "top_logprobs": {
                  " The answer is": -0.01756012998521328
                }
              },
              {
                "text": " B.",
                "logprob": -0.520246684551239,
                "top_logprobs": {
                  " B.": -0.520246684551239
                }
              },
              {
                "text": "",
                "logprob": -0.04820116609334946,
                "top_logprobs": {
                  "\n": -0.04820116609334946
                }
              },
              {
                "text": "",
                "logprob": -0.003082169685512781,
                "top_logprobs": {
                  "\n": -0.003082169685512781
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.35242629051208496,
        "request_datetime": 1672432881
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "The main reason people want to use wind as an energy source is not because there is",
        "references": [
          {
            "output": "make cookies",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "an everlasting supply",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id885"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "make cookies",
        "answer is B.": "an everlasting supply"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: The main reason people want to use wind as an energy source is not because there is\nA. make cookies\nB. an everlasting supply\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.7396556816529483,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.019993091002106667,
                "top_logprobs": {
                  " The answer is": -0.019993091002106667
                }
              },
              {
                "text": " B.",
                "logprob": -0.6725531220436096,
                "top_logprobs": {
                  " B.": -0.6725531220436096
                }
              },
              {
                "text": "",
                "logprob": -0.04463072493672371,
                "top_logprobs": {
                  "\n": -0.04463072493672371
                }
              },
              {
                "text": "",
                "logprob": -0.0024787436705082655,
                "top_logprobs": {
                  "\n": -0.0024787436705082655
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.41355204582214355,
        "request_datetime": 1672432881
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "A light isn't refracted when",
        "references": [
          {
            "output": "it shines at a mirror",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "it shines at a gem",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id773"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "it shines at a mirror",
        "answer is B.": "it shines at a gem"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: A light isn't refracted when\nA. it shines at a mirror\nB. it shines at a gem\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.6992706679739058,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.015910927206277847,
                "top_logprobs": {
                  " The answer is": -0.015910927206277847
                }
              },
              {
                "text": " B.",
                "logprob": -0.6572263240814209,
                "top_logprobs": {
                  " B.": -0.6572263240814209
                }
              },
              {
                "text": "",
                "logprob": -0.023780135437846184,
                "top_logprobs": {
                  "\n": -0.023780135437846184
                }
              },
              {
                "text": "",
                "logprob": -0.0023532812483608723,
                "top_logprobs": {
                  "\n": -0.0023532812483608723
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3303256034851074,
        "request_datetime": 1672432881
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "John Selden did not die in ___ ?",
        "references": [
          {
            "output": "manila",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "london",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id434"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "manila",
        "answer is B.": "london"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: John Selden did not die in ___ ?\nA. manila\nB. london\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9998846226371825,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.0398452989757061,
                "top_logprobs": {
                  " The answer is": -0.0398452989757061
                }
              },
              {
                "text": " B.",
                "logprob": -0.9064788818359375,
                "top_logprobs": {
                  " B.": -0.9064788818359375
                }
              },
              {
                "text": "",
                "logprob": -0.04767301306128502,
                "top_logprobs": {
                  "\n": -0.04767301306128502
                }
              },
              {
                "text": "",
                "logprob": -0.005887428764253855,
                "top_logprobs": {
                  "\n": -0.005887428764253855
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.32366490364074707,
        "request_datetime": 1672432881
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "adenine does not consist of ___ ?",
        "references": [
          {
            "output": "chocolate",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "nitrogen",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id485"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "chocolate",
        "answer is B.": "nitrogen"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: adenine does not consist of ___ ?\nA. chocolate\nB. nitrogen\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.8914787406101823,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.05990517884492874,
                "top_logprobs": {
                  " The answer is": -0.05990517884492874
                }
              },
              {
                "text": " B.",
                "logprob": -0.7719376683235168,
                "top_logprobs": {
                  " B.": -0.7719376683235168
                }
              },
              {
                "text": "",
                "logprob": -0.053835928440093994,
                "top_logprobs": {
                  "\n": -0.053835928440093994
                }
              },
              {
                "text": "",
                "logprob": -0.005799965001642704,
                "top_logprobs": {
                  "\n": -0.005799965001642704
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.37682437896728516,
        "request_datetime": 1672432881
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Kolkata Book Fair is not located in ___ ?",
        "references": [
          {
            "output": "chinatown",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "kolkata",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id262"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "chinatown",
        "answer is B.": "kolkata"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Kolkata Book Fair is not located in ___ ?\nA. chinatown\nB. kolkata\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.0815712115727365,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.11439578980207443,
                "top_logprobs": {
                  " The answer is": -0.11439578980207443
                }
              },
              {
                "text": " B.",
                "logprob": -0.9094997644424438,
                "top_logprobs": {
                  " B.": -0.9094997644424438
                }
              },
              {
                "text": "",
                "logprob": -0.05150112137198448,
                "top_logprobs": {
                  "\n": -0.05150112137198448
                }
              },
              {
                "text": "",
                "logprob": -0.00617453595623374,
                "top_logprobs": {
                  "\n": -0.00617453595623374
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3564581871032715,
        "request_datetime": 1672432881
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Fall is not ___?",
        "references": [
          {
            "output": "coming",
            "tags": []
          },
          {
            "output": "fearing",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id145"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "coming",
        "answer is B.": "fearing"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Fall is not ___?\nA. coming\nB. fearing\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is A.",
            "logprob": -1.0738730523735285,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.060473594814538956,
                "top_logprobs": {
                  " The answer is": -0.060473594814538956
                }
              },
              {
                "text": " A.",
                "logprob": -0.9575839042663574,
                "top_logprobs": {
                  " A.": -0.9575839042663574
                }
              },
              {
                "text": "",
                "logprob": -0.049803223460912704,
                "top_logprobs": {
                  "\n": -0.049803223460912704
                }
              },
              {
                "text": "",
                "logprob": -0.0060123298317193985,
                "top_logprobs": {
                  "\n": -0.0060123298317193985
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.32236671447753906,
        "request_datetime": 1672432881
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Maurice Joly is not a ___ by profession ?",
        "references": [
          {
            "output": "barrister",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "lawyer",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id495"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "barrister",
        "answer is B.": "lawyer"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Maurice Joly is not a ___ by profession ?\nA. barrister\nB. lawyer\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.6376401805318892,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.03743197023868561,
                "top_logprobs": {
                  " The answer is": -0.03743197023868561
                }
              },
              {
                "text": " B.",
                "logprob": -0.5683257579803467,
                "top_logprobs": {
                  " B.": -0.5683257579803467
                }
              },
              {
                "text": "",
                "logprob": -0.024418313056230545,
                "top_logprobs": {
                  "\n": -0.024418313056230545
                }
              },
              {
                "text": "",
                "logprob": -0.007464139256626368,
                "top_logprobs": {
                  "\n": -0.007464139256626368
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.41121745109558105,
        "request_datetime": 1672432882
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Sojitra is not a ___ ?",
        "references": [
          {
            "output": "village",
            "tags": []
          },
          {
            "output": "town",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id295"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "village",
        "answer is B.": "town"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Sojitra is not a ___ ?\nA. village\nB. town\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.0150935943238437,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04488503932952881,
                "top_logprobs": {
                  " The answer is": -0.04488503932952881
                }
              },
              {
                "text": " B.",
                "logprob": -0.9307312965393066,
                "top_logprobs": {
                  " B.": -0.9307312965393066
                }
              },
              {
                "text": "",
                "logprob": -0.03505378216505051,
                "top_logprobs": {
                  "\n": -0.03505378216505051
                }
              },
              {
                "text": "",
                "logprob": -0.004423476289957762,
                "top_logprobs": {
                  "\n": -0.004423476289957762
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.4517548084259033,
        "request_datetime": 1672432882
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Avoiding the use of fossil fuel is not an example of",
        "references": [
          {
            "output": "Ecosystem Vulnerability",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "Conservationism",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id837"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "Ecosystem Vulnerability",
        "answer is B.": "Conservationism"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Avoiding the use of fossil fuel is not an example of\nA. Ecosystem Vulnerability\nB. Conservationism\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.075507414760068,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.02315727435052395,
                "top_logprobs": {
                  " The answer is": -0.02315727435052395
                }
              },
              {
                "text": " B.",
                "logprob": -0.9953287243843079,
                "top_logprobs": {
                  " B.": -0.9953287243843079
                }
              },
              {
                "text": "",
                "logprob": -0.053999144583940506,
                "top_logprobs": {
                  "\n": -0.053999144583940506
                }
              },
              {
                "text": "",
                "logprob": -0.003022271441295743,
                "top_logprobs": {
                  "\n": -0.003022271441295743
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.4280819892883301,
        "request_datetime": 1672432882
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "The native language of Jean-Paul Sartre is not ___ ?",
        "references": [
          {
            "output": "french",
            "tags": []
          },
          {
            "output": "greek",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id364"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "french",
        "answer is B.": "greek"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: The native language of Jean-Paul Sartre is not ___ ?\nA. french\nB. greek\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.0503650028258562,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.07007038593292236,
                "top_logprobs": {
                  " The answer is": -0.07007038593292236
                }
              },
              {
                "text": " B.",
                "logprob": -0.9186978340148926,
                "top_logprobs": {
                  " B.": -0.9186978340148926
                }
              },
              {
                "text": "",
                "logprob": -0.055100519210100174,
                "top_logprobs": {
                  "\n": -0.055100519210100174
                }
              },
              {
                "text": "",
                "logprob": -0.0064962636679410934,
                "top_logprobs": {
                  "\n": -0.0064962636679410934
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.41048645973205566,
        "request_datetime": 1672432882
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Birds cannot ___?",
        "references": [
          {
            "output": "fly",
            "tags": []
          },
          {
            "output": "ulster",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id141"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "fly",
        "answer is B.": "ulster"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Birds cannot ___?\nA. fly\nB. ulster\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.7652161628939211,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.06233382597565651,
                "top_logprobs": {
                  " The answer is": -0.06233382597565651
                }
              },
              {
                "text": " B.",
                "logprob": -0.6616194844245911,
                "top_logprobs": {
                  " B.": -0.6616194844245911
                }
              },
              {
                "text": "",
                "logprob": -0.03413598984479904,
                "top_logprobs": {
                  "\n": -0.03413598984479904
                }
              },
              {
                "text": "",
                "logprob": -0.007126862648874521,
                "top_logprobs": {
                  "\n": -0.007126862648874521
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.40700364112854004,
        "request_datetime": 1672432882
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Worms are excellent decomposers not because",
        "references": [
          {
            "output": "worms enjoy eating dirt and decay",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "they enjoy eating carcasses and expel waste back to earth",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id867"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "worms enjoy eating dirt and decay",
        "answer is B.": "they enjoy eating carcasses and expel waste back to earth"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Worms are excellent decomposers not because\nA. worms enjoy eating dirt and decay\nB. they enjoy eating carcasses and expel waste back to earth\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.820292218355462,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.01769142970442772,
                "top_logprobs": {
                  " The answer is": -0.01769142970442772
                }
              },
              {
                "text": " B.",
                "logprob": -0.7539202570915222,
                "top_logprobs": {
                  " B.": -0.7539202570915222
                }
              },
              {
                "text": "",
                "logprob": -0.04647842049598694,
                "top_logprobs": {
                  "\n": -0.04647842049598694
                }
              },
              {
                "text": "",
                "logprob": -0.0022021110635250807,
                "top_logprobs": {
                  "\n": -0.0022021110635250807
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.32303786277770996,
        "request_datetime": 1672432882
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "The capital of Azerbaijan is not ___ ?",
        "references": [
          {
            "output": "baku",
            "tags": []
          },
          {
            "output": "kidnapped",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id612"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "baku",
        "answer is B.": "kidnapped"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: The capital of Azerbaijan is not ___ ?\nA. baku\nB. kidnapped\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is A.",
            "logprob": -1.1480769831687212,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.07798520475625992,
                "top_logprobs": {
                  " The answer is": -0.07798520475625992
                }
              },
              {
                "text": " A.",
                "logprob": -0.962478756904602,
                "top_logprobs": {
                  " A.": -0.962478756904602
                }
              },
              {
                "text": "",
                "logprob": -0.09955909848213196,
                "top_logprobs": {
                  "\n": -0.09955909848213196
                }
              },
              {
                "text": "",
                "logprob": -0.008053923025727272,
                "top_logprobs": {
                  "\n": -0.008053923025727272
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3849353790283203,
        "request_datetime": 1672432882
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "An electric car uses less gasoline than a regular car not because",
        "references": [
          {
            "output": "gas is unable to be used",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "power is prioritized over gas",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id855"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "gas is unable to be used",
        "answer is B.": "power is prioritized over gas"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: An electric car uses less gasoline than a regular car not because\nA. gas is unable to be used\nB. power is prioritized over gas\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.7872229390777647,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.020137624815106392,
                "top_logprobs": {
                  " The answer is": -0.020137624815106392
                }
              },
              {
                "text": " B.",
                "logprob": -0.7236568927764893,
                "top_logprobs": {
                  " B.": -0.7236568927764893
                }
              },
              {
                "text": "",
                "logprob": -0.03985709697008133,
                "top_logprobs": {
                  "\n": -0.03985709697008133
                }
              },
              {
                "text": "",
                "logprob": -0.0035713245160877705,
                "top_logprobs": {
                  "\n": -0.0035713245160877705
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.37787556648254395,
        "request_datetime": 1672432882
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "chicken nugget does not consist of ___ ?",
        "references": [
          {
            "output": "beef",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "chicken",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id279"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "beef",
        "answer is B.": "chicken"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: chicken nugget does not consist of ___ ?\nA. beef\nB. chicken\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.8314147810451686,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04830135405063629,
                "top_logprobs": {
                  " The answer is": -0.04830135405063629
                }
              },
              {
                "text": " B.",
                "logprob": -0.7323277592658997,
                "top_logprobs": {
                  " B.": -0.7323277592658997
                }
              },
              {
                "text": "",
                "logprob": -0.04464394971728325,
                "top_logprobs": {
                  "\n": -0.04464394971728325
                }
              },
              {
                "text": "",
                "logprob": -0.00614171801134944,
                "top_logprobs": {
                  "\n": -0.00614171801134944
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3266732692718506,
        "request_datetime": 1672432883
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "The native language of Eugene Kaspersky is not ___ ?",
        "references": [
          {
            "output": "russian",
            "tags": []
          },
          {
            "output": "korean",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id363"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "russian",
        "answer is B.": "korean"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: The native language of Eugene Kaspersky is not ___ ?\nA. russian\nB. korean\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9988699983805418,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.07023686170578003,
                "top_logprobs": {
                  " The answer is": -0.07023686170578003
                }
              },
              {
                "text": " B.",
                "logprob": -0.8597766757011414,
                "top_logprobs": {
                  " B.": -0.8597766757011414
                }
              },
              {
                "text": "",
                "logprob": -0.0613323338329792,
                "top_logprobs": {
                  "\n": -0.0613323338329792
                }
              },
              {
                "text": "",
                "logprob": -0.0075241271406412125,
                "top_logprobs": {
                  "\n": -0.0075241271406412125
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3360583782196045,
        "request_datetime": 1672432883
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Digital Audio Tape is not owned by ___ ?",
        "references": [
          {
            "output": "sony",
            "tags": []
          },
          {
            "output": "parsons",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id618"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "sony",
        "answer is B.": "parsons"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Digital Audio Tape is not owned by ___ ?\nA. sony\nB. parsons\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9502878347411752,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.06038886681199074,
                "top_logprobs": {
                  " The answer is": -0.06038886681199074
                }
              },
              {
                "text": " B.",
                "logprob": -0.8391516804695129,
                "top_logprobs": {
                  " B.": -0.8391516804695129
                }
              },
              {
                "text": "",
                "logprob": -0.043685171753168106,
                "top_logprobs": {
                  "\n": -0.043685171753168106
                }
              },
              {
                "text": "",
                "logprob": -0.007062115706503391,
                "top_logprobs": {
                  "\n": -0.007062115706503391
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3153667449951172,
        "request_datetime": 1672432883
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Lizards have not a ___?",
        "references": [
          {
            "output": "tail",
            "tags": []
          },
          {
            "output": "song",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id31"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "tail",
        "answer is B.": "song"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Lizards have not a ___?\nA. tail\nB. song\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.6529344064183533,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.045638713985681534,
                "top_logprobs": {
                  " The answer is": -0.045638713985681534
                }
              },
              {
                "text": " B.",
                "logprob": -0.5727499723434448,
                "top_logprobs": {
                  " B.": -0.5727499723434448
                }
              },
              {
                "text": "",
                "logprob": -0.030584027990698814,
                "top_logprobs": {
                  "\n": -0.030584027990698814
                }
              },
              {
                "text": "",
                "logprob": -0.003961692098528147,
                "top_logprobs": {
                  "\n": -0.003961692098528147
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.32918643951416016,
        "request_datetime": 1672432883
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "When the moon, sun, and earth line up, tides aren't at their",
        "references": [
          {
            "output": "Happy",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "Max",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id769"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "Happy",
        "answer is B.": "Max"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: When the moon, sun, and earth line up, tides aren't at their\nA. Happy\nB. Max\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.4994475704152137,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.014915610663592815,
                "top_logprobs": {
                  " The answer is": -0.014915610663592815
                }
              },
              {
                "text": " B.",
                "logprob": -0.40269649028778076,
                "top_logprobs": {
                  " B.": -0.40269649028778076
                }
              },
              {
                "text": "",
                "logprob": -0.07909562438726425,
                "top_logprobs": {
                  "\n": -0.07909562438726425
                }
              },
              {
                "text": "",
                "logprob": -0.0027398450765758753,
                "top_logprobs": {
                  "\n": -0.0027398450765758753
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3428511619567871,
        "request_datetime": 1672432883
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Jean Nicolas Pierre Hachette did not die in ___ ?",
        "references": [
          {
            "output": "navarro",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "paris",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id667"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "navarro",
        "answer is B.": "paris"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Jean Nicolas Pierre Hachette did not die in ___ ?\nA. navarro\nB. paris\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.971328744199127,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04938315227627754,
                "top_logprobs": {
                  " The answer is": -0.04938315227627754
                }
              },
              {
                "text": " B.",
                "logprob": -0.8720492124557495,
                "top_logprobs": {
                  " B.": -0.8720492124557495
                }
              },
              {
                "text": "",
                "logprob": -0.044233907014131546,
                "top_logprobs": {
                  "\n": -0.044233907014131546
                }
              },
              {
                "text": "",
                "logprob": -0.005662472452968359,
                "top_logprobs": {
                  "\n": -0.005662472452968359
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.4445991516113281,
        "request_datetime": 1672432883
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Rottendorf is not located in ___ ?",
        "references": [
          {
            "output": "germany",
            "tags": []
          },
          {
            "output": "croatia",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id436"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "germany",
        "answer is B.": "croatia"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Rottendorf is not located in ___ ?\nA. germany\nB. croatia\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.8972410745918751,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.06002778187394142,
                "top_logprobs": {
                  " The answer is": -0.06002778187394142
                }
              },
              {
                "text": " B.",
                "logprob": -0.7942415475845337,
                "top_logprobs": {
                  " B.": -0.7942415475845337
                }
              },
              {
                "text": "",
                "logprob": -0.03555469959974289,
                "top_logprobs": {
                  "\n": -0.03555469959974289
                }
              },
              {
                "text": "",
                "logprob": -0.007417045533657074,
                "top_logprobs": {
                  "\n": -0.007417045533657074
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.33771228790283203,
        "request_datetime": 1672432883
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "David Sainsbury, Baron Sainsbury of Turville never worked in ___ ?",
        "references": [
          {
            "output": "london",
            "tags": []
          },
          {
            "output": "director",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id656"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "london",
        "answer is B.": "director"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: David Sainsbury, Baron Sainsbury of Turville never worked in ___ ?\nA. london\nB. director\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9151738495565951,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.03135652467608452,
                "top_logprobs": {
                  " The answer is": -0.03135652467608452
                }
              },
              {
                "text": " B.",
                "logprob": -0.8345782160758972,
                "top_logprobs": {
                  " B.": -0.8345782160758972
                }
              },
              {
                "text": "",
                "logprob": -0.04196536913514137,
                "top_logprobs": {
                  "\n": -0.04196536913514137
                }
              },
              {
                "text": "",
                "logprob": -0.007273739669471979,
                "top_logprobs": {
                  "\n": -0.007273739669471979
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.37148427963256836,
        "request_datetime": 1672432884
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "ground beef is not a subclass of ___ ?",
        "references": [
          {
            "output": "beef",
            "tags": []
          },
          {
            "output": "pigs",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id338"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "beef",
        "answer is B.": "pigs"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: ground beef is not a subclass of ___ ?\nA. beef\nB. pigs\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.72601722413674,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.05269312486052513,
                "top_logprobs": {
                  " The answer is": -0.05269312486052513
                }
              },
              {
                "text": " B.",
                "logprob": -0.6296892166137695,
                "top_logprobs": {
                  " B.": -0.6296892166137695
                }
              },
              {
                "text": "",
                "logprob": -0.03804187476634979,
                "top_logprobs": {
                  "\n": -0.03804187476634979
                }
              },
              {
                "text": "",
                "logprob": -0.005593007896095514,
                "top_logprobs": {
                  "\n": -0.005593007896095514
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3422672748565674,
        "request_datetime": 1672432884
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "President of Ireland is not a legal term in ___ ?",
        "references": [
          {
            "output": "irish",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "ireland",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id346"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "irish",
        "answer is B.": "ireland"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: President of Ireland is not a legal term in ___ ?\nA. irish\nB. ireland\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.8082065740600228,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.06791156530380249,
                "top_logprobs": {
                  " The answer is": -0.06791156530380249
                }
              },
              {
                "text": " B.",
                "logprob": -0.6742688417434692,
                "top_logprobs": {
                  " B.": -0.6742688417434692
                }
              },
              {
                "text": "",
                "logprob": -0.056002434343099594,
                "top_logprobs": {
                  "\n": -0.056002434343099594
                }
              },
              {
                "text": "",
                "logprob": -0.010023732669651508,
                "top_logprobs": {
                  "\n": -0.010023732669651508
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.324371337890625,
        "request_datetime": 1672432884
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "The official language of Ruovesi is not ___ ?",
        "references": [
          {
            "output": "wrestled",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "finnish",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id602"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "wrestled",
        "answer is B.": "finnish"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: The official language of Ruovesi is not ___ ?\nA. wrestled\nB. finnish\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9342319914139807,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.03557759150862694,
                "top_logprobs": {
                  " The answer is": -0.03557759150862694
                }
              },
              {
                "text": " B.",
                "logprob": -0.8578592538833618,
                "top_logprobs": {
                  " B.": -0.8578592538833618
                }
              },
              {
                "text": "",
                "logprob": -0.03360508009791374,
                "top_logprobs": {
                  "\n": -0.03360508009791374
                }
              },
              {
                "text": "",
                "logprob": -0.007190065924078226,
                "top_logprobs": {
                  "\n": -0.007190065924078226
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3307373523712158,
        "request_datetime": 1672432884
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "A creature can hide in plain sight from predators not because",
        "references": [
          {
            "output": "it misdirects",
            "tags": []
          },
          {
            "output": "it burns",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id858"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "it misdirects",
        "answer is B.": "it burns"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: A creature can hide in plain sight from predators not because\nA. it misdirects\nB. it burns\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.7482963593211025,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.016095582395792007,
                "top_logprobs": {
                  " The answer is": -0.016095582395792007
                }
              },
              {
                "text": " B.",
                "logprob": -0.6964012980461121,
                "top_logprobs": {
                  " B.": -0.6964012980461121
                }
              },
              {
                "text": "",
                "logprob": -0.03256746008992195,
                "top_logprobs": {
                  "\n": -0.03256746008992195
                }
              },
              {
                "text": "",
                "logprob": -0.0032320187892764807,
                "top_logprobs": {
                  "\n": -0.0032320187892764807
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3893580436706543,
        "request_datetime": 1672432884
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Information is not a ___?",
        "references": [
          {
            "output": "beauty",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "commodity",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id97"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "beauty",
        "answer is B.": "commodity"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Information is not a ___?\nA. beauty\nB. commodity\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9132124073803425,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04323740303516388,
                "top_logprobs": {
                  " The answer is": -0.04323740303516388
                }
              },
              {
                "text": " B.",
                "logprob": -0.8325368762016296,
                "top_logprobs": {
                  " B.": -0.8325368762016296
                }
              },
              {
                "text": "",
                "logprob": -0.032681919634342194,
                "top_logprobs": {
                  "\n": -0.032681919634342194
                }
              },
              {
                "text": "",
                "logprob": -0.004756208509206772,
                "top_logprobs": {
                  "\n": -0.004756208509206772
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3927152156829834,
        "request_datetime": 1672432884
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "The native language of Jules Roy is not ___ ?",
        "references": [
          {
            "output": "french",
            "tags": []
          },
          {
            "output": "polish",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id196"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "french",
        "answer is B.": "polish"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: The native language of Jules Roy is not ___ ?\nA. french\nB. polish\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.8051416678354144,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.057514965534210205,
                "top_logprobs": {
                  " The answer is": -0.057514965534210205
                }
              },
              {
                "text": " B.",
                "logprob": -0.7052042484283447,
                "top_logprobs": {
                  " B.": -0.7052042484283447
                }
              },
              {
                "text": "",
                "logprob": -0.035414908081293106,
                "top_logprobs": {
                  "\n": -0.035414908081293106
                }
              },
              {
                "text": "",
                "logprob": -0.007007545791566372,
                "top_logprobs": {
                  "\n": -0.007007545791566372
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3496692180633545,
        "request_datetime": 1672432884
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "disruptive coloration is not a subclass of ___ ?",
        "references": [
          {
            "output": "insects",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "camouflage",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id342"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "insects",
        "answer is B.": "camouflage"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: disruptive coloration is not a subclass of ___ ?\nA. insects\nB. camouflage\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.0432895016856492,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.09526067227125168,
                "top_logprobs": {
                  " The answer is": -0.09526067227125168
                }
              },
              {
                "text": " B.",
                "logprob": -0.8967304229736328,
                "top_logprobs": {
                  " B.": -0.8967304229736328
                }
              },
              {
                "text": "",
                "logprob": -0.04563711956143379,
                "top_logprobs": {
                  "\n": -0.04563711956143379
                }
              },
              {
                "text": "",
                "logprob": -0.0056612868793308735,
                "top_logprobs": {
                  "\n": -0.0056612868793308735
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3411881923675537,
        "request_datetime": 1672432884
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Organisms cannot ___?",
        "references": [
          {
            "output": "teatro",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "die",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id101"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "teatro",
        "answer is B.": "die"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Organisms cannot ___?\nA. teatro\nB. die\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.0965306721627712,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.03706398978829384,
                "top_logprobs": {
                  " The answer is": -0.03706398978829384
                }
              },
              {
                "text": " B.",
                "logprob": -1.0189484357833862,
                "top_logprobs": {
                  " B.": -1.0189484357833862
                }
              },
              {
                "text": "",
                "logprob": -0.034272272139787674,
                "top_logprobs": {
                  "\n": -0.034272272139787674
                }
              },
              {
                "text": "",
                "logprob": -0.006245974451303482,
                "top_logprobs": {
                  "\n": -0.006245974451303482
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3377950191497803,
        "request_datetime": 1672432885
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Abdel Sattar Sabry does not play in ___ position ?",
        "references": [
          {
            "output": "wing",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "midfielder",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id272"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "wing",
        "answer is B.": "midfielder"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Abdel Sattar Sabry does not play in ___ position ?\nA. wing\nB. midfielder\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.1745428359135985,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04955344647169113,
                "top_logprobs": {
                  " The answer is": -0.04955344647169113
                }
              },
              {
                "text": " B.",
                "logprob": -1.0630096197128296,
                "top_logprobs": {
                  " B.": -1.0630096197128296
                }
              },
              {
                "text": "",
                "logprob": -0.049116019159555435,
                "top_logprobs": {
                  "\n": -0.049116019159555435
                }
              },
              {
                "text": "",
                "logprob": -0.01286375056952238,
                "top_logprobs": {
                  "\n": -0.01286375056952238
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3752741813659668,
        "request_datetime": 1672432885
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Some animals get caught easily by other animals not because they are slow while the predators are",
        "references": [
          {
            "output": "manipulative",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "speedy",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id891"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "manipulative",
        "answer is B.": "speedy"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Some animals get caught easily by other animals not because they are slow while the predators are\nA. manipulative\nB. speedy\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.7548761722864583,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.015713678672909737,
                "top_logprobs": {
                  " The answer is": -0.015713678672909737
                }
              },
              {
                "text": " B.",
                "logprob": -0.68644118309021,
                "top_logprobs": {
                  " B.": -0.68644118309021
                }
              },
              {
                "text": "",
                "logprob": -0.050803523510694504,
                "top_logprobs": {
                  "\n": -0.050803523510694504
                }
              },
              {
                "text": "",
                "logprob": -0.0019177870126441121,
                "top_logprobs": {
                  "\n": -0.0019177870126441121
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3236277103424072,
        "request_datetime": 1672432885
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Ano Liosia Olympic Hall is not located in ___ ?",
        "references": [
          {
            "output": "strikeouts",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "athens",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id741"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "strikeouts",
        "answer is B.": "athens"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Ano Liosia Olympic Hall is not located in ___ ?\nA. strikeouts\nB. athens\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.208471892401576,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.0529378205537796,
                "top_logprobs": {
                  " The answer is": -0.0529378205537796
                }
              },
              {
                "text": " B.",
                "logprob": -1.1007299423217773,
                "top_logprobs": {
                  " B.": -1.1007299423217773
                }
              },
              {
                "text": "",
                "logprob": -0.04849750176072121,
                "top_logprobs": {
                  "\n": -0.04849750176072121
                }
              },
              {
                "text": "",
                "logprob": -0.00630662776529789,
                "top_logprobs": {
                  "\n": -0.00630662776529789
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3359646797180176,
        "request_datetime": 1672432885
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Esko Aho does not work for ___ ?",
        "references": [
          {
            "output": "nintendo",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "nokia",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id529"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "nintendo",
        "answer is B.": "nokia"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Esko Aho does not work for ___ ?\nA. nintendo\nB. nokia\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9854114344343543,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.05547105893492699,
                "top_logprobs": {
                  " The answer is": -0.05547105893492699
                }
              },
              {
                "text": " B.",
                "logprob": -0.8719459176063538,
                "top_logprobs": {
                  " B.": -0.8719459176063538
                }
              },
              {
                "text": "",
                "logprob": -0.051425594836473465,
                "top_logprobs": {
                  "\n": -0.051425594836473465
                }
              },
              {
                "text": "",
                "logprob": -0.006568863056600094,
                "top_logprobs": {
                  "\n": -0.006568863056600094
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.35181450843811035,
        "request_datetime": 1672432885
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Riga and ___ are not twin cities ?",
        "references": [
          {
            "output": "tallinn",
            "tags": []
          },
          {
            "output": "augsburg",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id386"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "tallinn",
        "answer is B.": "augsburg"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Riga and ___ are not twin cities ?\nA. tallinn\nB. augsburg\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9024723637849092,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.05946304649114609,
                "top_logprobs": {
                  " The answer is": -0.05946304649114609
                }
              },
              {
                "text": " B.",
                "logprob": -0.7837159633636475,
                "top_logprobs": {
                  " B.": -0.7837159633636475
                }
              },
              {
                "text": "",
                "logprob": -0.05121779069304466,
                "top_logprobs": {
                  "\n": -0.05121779069304466
                }
              },
              {
                "text": "",
                "logprob": -0.008075563237071037,
                "top_logprobs": {
                  "\n": -0.008075563237071037
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.47278380393981934,
        "request_datetime": 1672432885
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "OKK Beograd is not located in ___ ?",
        "references": [
          {
            "output": "homosexual",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "belgrade",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id740"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "homosexual",
        "answer is B.": "belgrade"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: OKK Beograd is not located in ___ ?\nA. homosexual\nB. belgrade\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.6622454114258289,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.07936423271894455,
                "top_logprobs": {
                  " The answer is": -0.07936423271894455
                }
              },
              {
                "text": " B.",
                "logprob": -0.5208673477172852,
                "top_logprobs": {
                  " B.": -0.5208673477172852
                }
              },
              {
                "text": "",
                "logprob": -0.05259360000491142,
                "top_logprobs": {
                  "\n": -0.05259360000491142
                }
              },
              {
                "text": "",
                "logprob": -0.009420230984687805,
                "top_logprobs": {
                  "\n": -0.009420230984687805
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3416779041290283,
        "request_datetime": 1672432885
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Canjuers is not located in ___ ?",
        "references": [
          {
            "output": "bordeaux",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "france",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id215"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "bordeaux",
        "answer is B.": "france"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Canjuers is not located in ___ ?\nA. bordeaux\nB. france\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9642642186954618,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.06519929319620132,
                "top_logprobs": {
                  " The answer is": -0.06519929319620132
                }
              },
              {
                "text": " B.",
                "logprob": -0.8557802438735962,
                "top_logprobs": {
                  " B.": -0.8557802438735962
                }
              },
              {
                "text": "",
                "logprob": -0.03600005432963371,
                "top_logprobs": {
                  "\n": -0.03600005432963371
                }
              },
              {
                "text": "",
                "logprob": -0.007284627296030521,
                "top_logprobs": {
                  "\n": -0.007284627296030521
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.4174351692199707,
        "request_datetime": 1672432885
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Child does not want ___?",
        "references": [
          {
            "output": "lab",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "love",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id77"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "lab",
        "answer is B.": "love"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Child does not want ___?\nA. lab\nB. love\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.1165399001911283,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04178394004702568,
                "top_logprobs": {
                  " The answer is": -0.04178394004702568
                }
              },
              {
                "text": " B.",
                "logprob": -1.0205676555633545,
                "top_logprobs": {
                  " B.": -1.0205676555633545
                }
              },
              {
                "text": "",
                "logprob": -0.048111870884895325,
                "top_logprobs": {
                  "\n": -0.048111870884895325
                }
              },
              {
                "text": "",
                "logprob": -0.0060764336958527565,
                "top_logprobs": {
                  "\n": -0.0060764336958527565
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3292427062988281,
        "request_datetime": 1672432886
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Tungsten is a metal which is found in large amounts in filaments, which are used in incandescent light bulbs. These light bulbs work not because",
        "references": [
          {
            "output": "the filament glows warmly",
            "tags": []
          },
          {
            "output": "light bulbs get very warm",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id940"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "the filament glows warmly",
        "answer is B.": "light bulbs get very warm"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Tungsten is a metal which is found in large amounts in filaments, which are used in incandescent light bulbs. These light bulbs work not because\nA. the filament glows warmly\nB. light bulbs get very warm\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.7919734071474522,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.026517674326896667,
                "top_logprobs": {
                  " The answer is": -0.026517674326896667
                }
              },
              {
                "text": " B.",
                "logprob": -0.7034558057785034,
                "top_logprobs": {
                  " B.": -0.7034558057785034
                }
              },
              {
                "text": "",
                "logprob": -0.058973852545022964,
                "top_logprobs": {
                  "\n": -0.058973852545022964
                }
              },
              {
                "text": "",
                "logprob": -0.0030260744970291853,
                "top_logprobs": {
                  "\n": -0.0030260744970291853
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3247537612915039,
        "request_datetime": 1672432886
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Apple Thunderbolt Display is not developed by ___ ?",
        "references": [
          {
            "output": "intel",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "apple",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id239"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "intel",
        "answer is B.": "apple"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Apple Thunderbolt Display is not developed by ___ ?\nA. intel\nB. apple\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9768909430131316,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04848955199122429,
                "top_logprobs": {
                  " The answer is": -0.04848955199122429
                }
              },
              {
                "text": " B.",
                "logprob": -0.8753266334533691,
                "top_logprobs": {
                  " B.": -0.8753266334533691
                }
              },
              {
                "text": "",
                "logprob": -0.0433138906955719,
                "top_logprobs": {
                  "\n": -0.0433138906955719
                }
              },
              {
                "text": "",
                "logprob": -0.00976086687296629,
                "top_logprobs": {
                  "\n": -0.00976086687296629
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.33113718032836914,
        "request_datetime": 1672432886
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Funkadelic does not play ___ music ?",
        "references": [
          {
            "output": "strips",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "funk",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id687"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "strips",
        "answer is B.": "funk"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Funkadelic does not play ___ music ?\nA. strips\nB. funk\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.7038589706644416,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.032957401126623154,
                "top_logprobs": {
                  " The answer is": -0.032957401126623154
                }
              },
              {
                "text": " B.",
                "logprob": -0.6144492030143738,
                "top_logprobs": {
                  " B.": -0.6144492030143738
                }
              },
              {
                "text": "",
                "logprob": -0.046632830053567886,
                "top_logprobs": {
                  "\n": -0.046632830053567886
                }
              },
              {
                "text": "",
                "logprob": -0.009819536469876766,
                "top_logprobs": {
                  "\n": -0.009819536469876766
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.33066821098327637,
        "request_datetime": 1672432886
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Morice River is not a ___ ?",
        "references": [
          {
            "output": "muscle",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "river",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id452"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "muscle",
        "answer is B.": "river"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Morice River is not a ___ ?\nA. muscle\nB. river\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.0036206124350429,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.052232060581445694,
                "top_logprobs": {
                  " The answer is": -0.052232060581445694
                }
              },
              {
                "text": " B.",
                "logprob": -0.9110060334205627,
                "top_logprobs": {
                  " B.": -0.9110060334205627
                }
              },
              {
                "text": "",
                "logprob": -0.03184659406542778,
                "top_logprobs": {
                  "\n": -0.03184659406542778
                }
              },
              {
                "text": "",
                "logprob": -0.00853592436760664,
                "top_logprobs": {
                  "\n": -0.00853592436760664
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3291757106781006,
        "request_datetime": 1672432886
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "one inherited characteristic of fur isn't it's",
        "references": [
          {
            "output": "hue",
            "tags": []
          },
          {
            "output": "weight",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id798"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "hue",
        "answer is B.": "weight"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: one inherited characteristic of fur isn't it's\nA. hue\nB. weight\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9605748385656625,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.06468787044286728,
                "top_logprobs": {
                  " The answer is": -0.06468787044286728
                }
              },
              {
                "text": " B.",
                "logprob": -0.8632596731185913,
                "top_logprobs": {
                  " B.": -0.8632596731185913
                }
              },
              {
                "text": "",
                "logprob": -0.02957138977944851,
                "top_logprobs": {
                  "\n": -0.02957138977944851
                }
              },
              {
                "text": "",
                "logprob": -0.0030559052247554064,
                "top_logprobs": {
                  "\n": -0.0030559052247554064
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.6631350517272949,
        "request_datetime": 1672432886
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Salvadoran Football Federation is not a member of ___ ?",
        "references": [
          {
            "output": "fifa",
            "tags": []
          },
          {
            "output": "uefa",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id200"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "fifa",
        "answer is B.": "uefa"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Salvadoran Football Federation is not a member of ___ ?\nA. fifa\nB. uefa\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is A.",
            "logprob": -1.241548559628427,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.03956139460206032,
                "top_logprobs": {
                  " The answer is": -0.03956139460206032
                }
              },
              {
                "text": " A.",
                "logprob": -1.11702561378479,
                "top_logprobs": {
                  " A.": -1.11702561378479
                }
              },
              {
                "text": "",
                "logprob": -0.07690136134624481,
                "top_logprobs": {
                  "\n": -0.07690136134624481
                }
              },
              {
                "text": "",
                "logprob": -0.00806018989533186,
                "top_logprobs": {
                  "\n": -0.00806018989533186
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3366382122039795,
        "request_datetime": 1672432887
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Biblioteka Dlya Chteniya was not written in ___ ?",
        "references": [
          {
            "output": "russian",
            "tags": []
          },
          {
            "output": "helpful",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id622"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "russian",
        "answer is B.": "helpful"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Biblioteka Dlya Chteniya was not written in ___ ?\nA. russian\nB. helpful\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.0965334363281727,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.06080692633986473,
                "top_logprobs": {
                  " The answer is": -0.06080692633986473
                }
              },
              {
                "text": " B.",
                "logprob": -0.9828610420227051,
                "top_logprobs": {
                  " B.": -0.9828610420227051
                }
              },
              {
                "text": "",
                "logprob": -0.04779905453324318,
                "top_logprobs": {
                  "\n": -0.04779905453324318
                }
              },
              {
                "text": "",
                "logprob": -0.0050664134323596954,
                "top_logprobs": {
                  "\n": -0.0050664134323596954
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.34505367279052734,
        "request_datetime": 1672432887
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Pete Lesperance does not play ___ ?",
        "references": [
          {
            "output": "guitar",
            "tags": []
          },
          {
            "output": "trombone",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id524"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "guitar",
        "answer is B.": "trombone"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Pete Lesperance does not play ___ ?\nA. guitar\nB. trombone\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.7658996749669313,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04524548351764679,
                "top_logprobs": {
                  " The answer is": -0.04524548351764679
                }
              },
              {
                "text": " B.",
                "logprob": -0.6666972041130066,
                "top_logprobs": {
                  " B.": -0.6666972041130066
                }
              },
              {
                "text": "",
                "logprob": -0.04439482092857361,
                "top_logprobs": {
                  "\n": -0.04439482092857361
                }
              },
              {
                "text": "",
                "logprob": -0.009562166407704353,
                "top_logprobs": {
                  "\n": -0.009562166407704353
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3544771671295166,
        "request_datetime": 1672432887
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Ohio House of Representatives is not a legal term in ___ ?",
        "references": [
          {
            "output": "delaware",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "ohio",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id345"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "delaware",
        "answer is B.": "ohio"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Ohio House of Representatives is not a legal term in ___ ?\nA. delaware\nB. ohio\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.0748980245552957,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.03461456671357155,
                "top_logprobs": {
                  " The answer is": -0.03461456671357155
                }
              },
              {
                "text": " B.",
                "logprob": -0.9795914888381958,
                "top_logprobs": {
                  " B.": -0.9795914888381958
                }
              },
              {
                "text": "",
                "logprob": -0.05414098873734474,
                "top_logprobs": {
                  "\n": -0.05414098873734474
                }
              },
              {
                "text": "",
                "logprob": -0.006550980266183615,
                "top_logprobs": {
                  "\n": -0.006550980266183615
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3387589454650879,
        "request_datetime": 1672432887
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Jonathan Haidt does not work in the field of ___ ?",
        "references": [
          {
            "output": "music",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "psychology",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id252"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "music",
        "answer is B.": "psychology"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Jonathan Haidt does not work in the field of ___ ?\nA. music\nB. psychology\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.754795525688678,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.06553027778863907,
                "top_logprobs": {
                  " The answer is": -0.06553027778863907
                }
              },
              {
                "text": " B.",
                "logprob": -0.6465017795562744,
                "top_logprobs": {
                  " B.": -0.6465017795562744
                }
              },
              {
                "text": "",
                "logprob": -0.035624414682388306,
                "top_logprobs": {
                  "\n": -0.035624414682388306
                }
              },
              {
                "text": "",
                "logprob": -0.007139053661376238,
                "top_logprobs": {
                  "\n": -0.007139053661376238
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3278379440307617,
        "request_datetime": 1672432887
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Internet Archive was not written in ___ ?",
        "references": [
          {
            "output": "english",
            "tags": []
          },
          {
            "output": "polish",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id319"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "english",
        "answer is B.": "polish"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Internet Archive was not written in ___ ?\nA. english\nB. polish\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.0727417031303048,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.048741865903139114,
                "top_logprobs": {
                  " The answer is": -0.048741865903139114
                }
              },
              {
                "text": " B.",
                "logprob": -0.9477798938751221,
                "top_logprobs": {
                  " B.": -0.9477798938751221
                }
              },
              {
                "text": "",
                "logprob": -0.06833584606647491,
                "top_logprobs": {
                  "\n": -0.06833584606647491
                }
              },
              {
                "text": "",
                "logprob": -0.007884097285568714,
                "top_logprobs": {
                  "\n": -0.007884097285568714
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3174457550048828,
        "request_datetime": 1672432887
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Teres Ridge is not located in ___ ?",
        "references": [
          {
            "output": "antarctica",
            "tags": []
          },
          {
            "output": "europe",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id478"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "antarctica",
        "answer is B.": "europe"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Teres Ridge is not located in ___ ?\nA. antarctica\nB. europe\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is A.",
            "logprob": -1.042962112929672,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.06498327106237411,
                "top_logprobs": {
                  " The answer is": -0.06498327106237411
                }
              },
              {
                "text": " A.",
                "logprob": -0.9367460012435913,
                "top_logprobs": {
                  " A.": -0.9367460012435913
                }
              },
              {
                "text": "",
                "logprob": -0.03630129247903824,
                "top_logprobs": {
                  "\n": -0.03630129247903824
                }
              },
              {
                "text": "",
                "logprob": -0.004931548144668341,
                "top_logprobs": {
                  "\n": -0.004931548144668341
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3177671432495117,
        "request_datetime": 1672432887
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Joseph Clay was not born in ___ ?",
        "references": [
          {
            "output": "ponce",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "philadelphia",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id382"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "ponce",
        "answer is B.": "philadelphia"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Joseph Clay was not born in ___ ?\nA. ponce\nB. philadelphia\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.1810798170045018,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.06498181819915771,
                "top_logprobs": {
                  " The answer is": -0.06498181819915771
                }
              },
              {
                "text": " B.",
                "logprob": -1.0565414428710938,
                "top_logprobs": {
                  " B.": -1.0565414428710938
                }
              },
              {
                "text": "",
                "logprob": -0.05120136961340904,
                "top_logprobs": {
                  "\n": -0.05120136961340904
                }
              },
              {
                "text": "",
                "logprob": -0.008355186320841312,
                "top_logprobs": {
                  "\n": -0.008355186320841312
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3684120178222656,
        "request_datetime": 1672432888
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "One of the reasons some species go extinct is not because predators",
        "references": [
          {
            "output": "go dancing with them",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "murder too many of them",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id869"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "go dancing with them",
        "answer is B.": "murder too many of them"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: One of the reasons some species go extinct is not because predators\nA. go dancing with them\nB. murder too many of them\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.7833748327102512,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.01638270728290081,
                "top_logprobs": {
                  " The answer is": -0.01638270728290081
                }
              },
              {
                "text": " B.",
                "logprob": -0.7236084342002869,
                "top_logprobs": {
                  " B.": -0.7236084342002869
                }
              },
              {
                "text": "",
                "logprob": -0.04083431512117386,
                "top_logprobs": {
                  "\n": -0.04083431512117386
                }
              },
              {
                "text": "",
                "logprob": -0.002549376105889678,
                "top_logprobs": {
                  "\n": -0.002549376105889678
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3759000301361084,
        "request_datetime": 1672432888
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Cans cannot be ___?",
        "references": [
          {
            "output": "impressed",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "recycled",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id55"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "impressed",
        "answer is B.": "recycled"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Cans cannot be ___?\nA. impressed\nB. recycled\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.8778513283468783,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04234309121966362,
                "top_logprobs": {
                  " The answer is": -0.04234309121966362
                }
              },
              {
                "text": " B.",
                "logprob": -0.8096911907196045,
                "top_logprobs": {
                  " B.": -0.8096911907196045
                }
              },
              {
                "text": "",
                "logprob": -0.02244054712355137,
                "top_logprobs": {
                  "\n": -0.02244054712355137
                }
              },
              {
                "text": "",
                "logprob": -0.0033764992840588093,
                "top_logprobs": {
                  "\n": -0.0033764992840588093
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.37528347969055176,
        "request_datetime": 1672432888
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Lev Naumov does not play ___ ?",
        "references": [
          {
            "output": "piano",
            "tags": []
          },
          {
            "output": "harp",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id522"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "piano",
        "answer is B.": "harp"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Lev Naumov does not play ___ ?\nA. piano\nB. harp\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.6336833946406841,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.06113678216934204,
                "top_logprobs": {
                  " The answer is": -0.06113678216934204
                }
              },
              {
                "text": " B.",
                "logprob": -0.5235268473625183,
                "top_logprobs": {
                  " B.": -0.5235268473625183
                }
              },
              {
                "text": "",
                "logprob": -0.03971916809678078,
                "top_logprobs": {
                  "\n": -0.03971916809678078
                }
              },
              {
                "text": "",
                "logprob": -0.009300597012043,
                "top_logprobs": {
                  "\n": -0.009300597012043
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.37253308296203613,
        "request_datetime": 1672432888
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Tom Cruise is not affiliated with the ___ religion ?",
        "references": [
          {
            "output": "scientology",
            "tags": []
          },
          {
            "output": "islam",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id175"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "scientology",
        "answer is B.": "islam"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Tom Cruise is not affiliated with the ___ religion ?\nA. scientology\nB. islam\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9586090687662363,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04906187951564789,
                "top_logprobs": {
                  " The answer is": -0.04906187951564789
                }
              },
              {
                "text": " B.",
                "logprob": -0.8401576280593872,
                "top_logprobs": {
                  " B.": -0.8401576280593872
                }
              },
              {
                "text": "",
                "logprob": -0.059728216379880905,
                "top_logprobs": {
                  "\n": -0.059728216379880905
                }
              },
              {
                "text": "",
                "logprob": -0.009661344811320305,
                "top_logprobs": {
                  "\n": -0.009661344811320305
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3327615261077881,
        "request_datetime": 1672432888
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Anti-Oedipus does not work in the field of ___ ?",
        "references": [
          {
            "output": "philosophy",
            "tags": []
          },
          {
            "output": "algebra",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id413"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "philosophy",
        "answer is B.": "algebra"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Anti-Oedipus does not work in the field of ___ ?\nA. philosophy\nB. algebra\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.7766206292435527,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04788496717810631,
                "top_logprobs": {
                  " The answer is": -0.04788496717810631
                }
              },
              {
                "text": " B.",
                "logprob": -0.6777017712593079,
                "top_logprobs": {
                  " B.": -0.6777017712593079
                }
              },
              {
                "text": "",
                "logprob": -0.042605530470609665,
                "top_logprobs": {
                  "\n": -0.042605530470609665
                }
              },
              {
                "text": "",
                "logprob": -0.00842836033552885,
                "top_logprobs": {
                  "\n": -0.00842836033552885
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3193473815917969,
        "request_datetime": 1672432888
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Two wheeled conveyances are not held together by",
        "references": [
          {
            "output": "glue",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "helically ridged pins",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id753"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "glue",
        "answer is B.": "helically ridged pins"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Two wheeled conveyances are not held together by\nA. glue\nB. helically ridged pins\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.5897541618905962,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.017303690314292908,
                "top_logprobs": {
                  " The answer is": -0.017303690314292908
                }
              },
              {
                "text": " B.",
                "logprob": -0.5412576198577881,
                "top_logprobs": {
                  " B.": -0.5412576198577881
                }
              },
              {
                "text": "",
                "logprob": -0.028263762593269348,
                "top_logprobs": {
                  "\n": -0.028263762593269348
                }
              },
              {
                "text": "",
                "logprob": -0.0029290891252458096,
                "top_logprobs": {
                  "\n": -0.0029290891252458096
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3300154209136963,
        "request_datetime": 1672432888
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Louisiana Voodoo was not founded in ___ ?",
        "references": [
          {
            "output": "nagoya",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "louisiana",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id516"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "nagoya",
        "answer is B.": "louisiana"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Louisiana Voodoo was not founded in ___ ?\nA. nagoya\nB. louisiana\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9543187711387873,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04345531761646271,
                "top_logprobs": {
                  " The answer is": -0.04345531761646271
                }
              },
              {
                "text": " B.",
                "logprob": -0.8492692708969116,
                "top_logprobs": {
                  " B.": -0.8492692708969116
                }
              },
              {
                "text": "",
                "logprob": -0.053910933434963226,
                "top_logprobs": {
                  "\n": -0.053910933434963226
                }
              },
              {
                "text": "",
                "logprob": -0.007683249190449715,
                "top_logprobs": {
                  "\n": -0.007683249190449715
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.32067155838012695,
        "request_datetime": 1672432888
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Animator.ru was not created in ___ ?",
        "references": [
          {
            "output": "russia",
            "tags": []
          },
          {
            "output": "argentina",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id535"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "russia",
        "answer is B.": "argentina"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Animator.ru was not created in ___ ?\nA. russia\nB. argentina\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.115803531371057,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.06501120328903198,
                "top_logprobs": {
                  " The answer is": -0.06501120328903198
                }
              },
              {
                "text": " B.",
                "logprob": -0.9793088436126709,
                "top_logprobs": {
                  " B.": -0.9793088436126709
                }
              },
              {
                "text": "",
                "logprob": -0.06278611719608307,
                "top_logprobs": {
                  "\n": -0.06278611719608307
                }
              },
              {
                "text": "",
                "logprob": -0.008697367273271084,
                "top_logprobs": {
                  "\n": -0.008697367273271084
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3232917785644531,
        "request_datetime": 1672432889
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Dan Sealey does not play ___ ?",
        "references": [
          {
            "output": "guitar",
            "tags": []
          },
          {
            "output": "pipe organ",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id521"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "guitar",
        "answer is B.": "pipe organ"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Dan Sealey does not play ___ ?\nA. guitar\nB. pipe organ\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.8469730643555522,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04262951761484146,
                "top_logprobs": {
                  " The answer is": -0.04262951761484146
                }
              },
              {
                "text": " B.",
                "logprob": -0.7432001233100891,
                "top_logprobs": {
                  " B.": -0.7432001233100891
                }
              },
              {
                "text": "",
                "logprob": -0.050497326999902725,
                "top_logprobs": {
                  "\n": -0.050497326999902725
                }
              },
              {
                "text": "",
                "logprob": -0.010646096430718899,
                "top_logprobs": {
                  "\n": -0.010646096430718899
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.32555675506591797,
        "request_datetime": 1672432889
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Football Association of Brunei Darussalam is not a member of ___ ?",
        "references": [
          {
            "output": "fifa",
            "tags": []
          },
          {
            "output": "application",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id710"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "fifa",
        "answer is B.": "application"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Football Association of Brunei Darussalam is not a member of ___ ?\nA. fifa\nB. application\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.269979052245617,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.059123311191797256,
                "top_logprobs": {
                  " The answer is": -0.059123311191797256
                }
              },
              {
                "text": " B.",
                "logprob": -1.1373006105422974,
                "top_logprobs": {
                  " B.": -1.1373006105422974
                }
              },
              {
                "text": "",
                "logprob": -0.0663900375366211,
                "top_logprobs": {
                  "\n": -0.0663900375366211
                }
              },
              {
                "text": "",
                "logprob": -0.007165092974901199,
                "top_logprobs": {
                  "\n": -0.007165092974901199
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3276982307434082,
        "request_datetime": 1672432889
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "The leading cause of soil and rock erosion is not",
        "references": [
          {
            "output": "NaCl",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "H2O",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id815"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "NaCl",
        "answer is B.": "H2O"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: The leading cause of soil and rock erosion is not\nA. NaCl\nB. H2O\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.8668876066803932,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.01641073450446129,
                "top_logprobs": {
                  " The answer is": -0.01641073450446129
                }
              },
              {
                "text": " B.",
                "logprob": -0.8064243793487549,
                "top_logprobs": {
                  " B.": -0.8064243793487549
                }
              },
              {
                "text": "",
                "logprob": -0.0399891659617424,
                "top_logprobs": {
                  "\n": -0.0399891659617424
                }
              },
              {
                "text": "",
                "logprob": -0.004063326865434647,
                "top_logprobs": {
                  "\n": -0.004063326865434647
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3433871269226074,
        "request_datetime": 1672432889
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Cyprus is not an ___?",
        "references": [
          {
            "output": "accessory",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "island",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id65"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "accessory",
        "answer is B.": "island"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Cyprus is not an ___?\nA. accessory\nB. island\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is A.",
            "logprob": -1.1520776976831257,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.05263160169124603,
                "top_logprobs": {
                  " The answer is": -0.05263160169124603
                }
              },
              {
                "text": " A.",
                "logprob": -1.0467643737792969,
                "top_logprobs": {
                  " A.": -1.0467643737792969
                }
              },
              {
                "text": "",
                "logprob": -0.046864453703165054,
                "top_logprobs": {
                  "\n": -0.046864453703165054
                }
              },
              {
                "text": "",
                "logprob": -0.005817268509417772,
                "top_logprobs": {
                  "\n": -0.005817268509417772
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3297414779663086,
        "request_datetime": 1672432889
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Cape Town and ___ are not twin cities ?",
        "references": [
          {
            "output": "johannesburg",
            "tags": []
          },
          {
            "output": "jerusalem",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id385"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "johannesburg",
        "answer is B.": "jerusalem"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Cape Town and ___ are not twin cities ?\nA. johannesburg\nB. jerusalem\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.7346012257039547,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.07923538982868195,
                "top_logprobs": {
                  " The answer is": -0.07923538982868195
                }
              },
              {
                "text": " B.",
                "logprob": -0.5830633044242859,
                "top_logprobs": {
                  " B.": -0.5830633044242859
                }
              },
              {
                "text": "",
                "logprob": -0.06533073633909225,
                "top_logprobs": {
                  "\n": -0.06533073633909225
                }
              },
              {
                "text": "",
                "logprob": -0.0069717951118946075,
                "top_logprobs": {
                  "\n": -0.0069717951118946075
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.32645344734191895,
        "request_datetime": 1672432889
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "The Earth's closest heat source isn't",
        "references": [
          {
            "output": "our celestial fireball",
            "tags": []
          },
          {
            "output": "gamma rays",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id822"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "our celestial fireball",
        "answer is B.": "gamma rays"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: The Earth's closest heat source isn't\nA. our celestial fireball\nB. gamma rays\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.8225381029769778,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.01133785117417574,
                "top_logprobs": {
                  " The answer is": -0.01133785117417574
                }
              },
              {
                "text": " B.",
                "logprob": -0.7729657292366028,
                "top_logprobs": {
                  " B.": -0.7729657292366028
                }
              },
              {
                "text": "",
                "logprob": -0.03505942225456238,
                "top_logprobs": {
                  "\n": -0.03505942225456238
                }
              },
              {
                "text": "",
                "logprob": -0.0031751003116369247,
                "top_logprobs": {
                  "\n": -0.0031751003116369247
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.4814186096191406,
        "request_datetime": 1672432889
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Cars are big polluters not because they release toxins from the gas into the air making it",
        "references": [
          {
            "output": "space",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "unhealthy to breathe",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id941"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "space",
        "answer is B.": "unhealthy to breathe"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Cars are big polluters not because they release toxins from the gas into the air making it\nA. space\nB. unhealthy to breathe\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is A.",
            "logprob": -0.9052664290647954,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.02034100890159607,
                "top_logprobs": {
                  " The answer is": -0.02034100890159607
                }
              },
              {
                "text": " A.",
                "logprob": -0.832168698310852,
                "top_logprobs": {
                  " A.": -0.832168698310852
                }
              },
              {
                "text": "",
                "logprob": -0.048897743225097656,
                "top_logprobs": {
                  "\n": -0.048897743225097656
                }
              },
              {
                "text": "",
                "logprob": -0.0038589786272495985,
                "top_logprobs": {
                  "\n": -0.0038589786272495985
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.40496015548706055,
        "request_datetime": 1672432889
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Italy does not maintain diplomatic relations with ___ ?",
        "references": [
          {
            "output": "lebanon",
            "tags": []
          },
          {
            "output": "insights",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id582"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "lebanon",
        "answer is B.": "insights"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Italy does not maintain diplomatic relations with ___ ?\nA. lebanon\nB. insights\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9714138642884791,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.03873925283551216,
                "top_logprobs": {
                  " The answer is": -0.03873925283551216
                }
              },
              {
                "text": " B.",
                "logprob": -0.8882555961608887,
                "top_logprobs": {
                  " B.": -0.8882555961608887
                }
              },
              {
                "text": "",
                "logprob": -0.038150887936353683,
                "top_logprobs": {
                  "\n": -0.038150887936353683
                }
              },
              {
                "text": "",
                "logprob": -0.006268127355724573,
                "top_logprobs": {
                  "\n": -0.006268127355724573
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3201322555541992,
        "request_datetime": 1672432890
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Heribert of Cologne has not the position of ___ ?",
        "references": [
          {
            "output": "mayor",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "archbishop",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id362"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "mayor",
        "answer is B.": "archbishop"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Heribert of Cologne has not the position of ___ ?\nA. mayor\nB. archbishop\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.0142772691324353,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04735039547085762,
                "top_logprobs": {
                  " The answer is": -0.04735039547085762
                }
              },
              {
                "text": " B.",
                "logprob": -0.9114805459976196,
                "top_logprobs": {
                  " B.": -0.9114805459976196
                }
              },
              {
                "text": "",
                "logprob": -0.04871688783168793,
                "top_logprobs": {
                  "\n": -0.04871688783168793
                }
              },
              {
                "text": "",
                "logprob": -0.006729439832270145,
                "top_logprobs": {
                  "\n": -0.006729439832270145
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3211798667907715,
        "request_datetime": 1672432890
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Parippally is not located in ___ ?",
        "references": [
          {
            "output": "propagation",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "india",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id597"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "propagation",
        "answer is B.": "india"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Parippally is not located in ___ ?\nA. propagation\nB. india\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.1542817810550332,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.06492127478122711,
                "top_logprobs": {
                  " The answer is": -0.06492127478122711
                }
              },
              {
                "text": " B.",
                "logprob": -1.0296950340270996,
                "top_logprobs": {
                  " B.": -1.0296950340270996
                }
              },
              {
                "text": "",
                "logprob": -0.05111891031265259,
                "top_logprobs": {
                  "\n": -0.05111891031265259
                }
              },
              {
                "text": "",
                "logprob": -0.008546561934053898,
                "top_logprobs": {
                  "\n": -0.008546561934053898
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.363710880279541,
        "request_datetime": 1672432890
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Which of these isn't less likely to cause pollution",
        "references": [
          {
            "output": "chopper",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "mountain bike",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id829"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "chopper",
        "answer is B.": "mountain bike"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Which of these isn't less likely to cause pollution\nA. chopper\nB. mountain bike\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.8393438667990267,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.031833890825510025,
                "top_logprobs": {
                  " The answer is": -0.031833890825510025
                }
              },
              {
                "text": " B.",
                "logprob": -0.7723487615585327,
                "top_logprobs": {
                  " B.": -0.7723487615585327
                }
              },
              {
                "text": "",
                "logprob": -0.030424345284700394,
                "top_logprobs": {
                  "\n": -0.030424345284700394
                }
              },
              {
                "text": "",
                "logprob": -0.004736869130283594,
                "top_logprobs": {
                  "\n": -0.004736869130283594
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.32800817489624023,
        "request_datetime": 1672432890
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "National Film Board of Canada does not work in the field of ___ ?",
        "references": [
          {
            "output": "animation",
            "tags": []
          },
          {
            "output": "art",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id415"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "animation",
        "answer is B.": "art"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: National Film Board of Canada does not work in the field of ___ ?\nA. animation\nB. art\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9626976242288947,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.03126213327050209,
                "top_logprobs": {
                  " The answer is": -0.03126213327050209
                }
              },
              {
                "text": " B.",
                "logprob": -0.8623687624931335,
                "top_logprobs": {
                  " B.": -0.8623687624931335
                }
              },
              {
                "text": "",
                "logprob": -0.06060408800840378,
                "top_logprobs": {
                  "\n": -0.06060408800840378
                }
              },
              {
                "text": "",
                "logprob": -0.008462640456855297,
                "top_logprobs": {
                  "\n": -0.008462640456855297
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3202524185180664,
        "request_datetime": 1672432890
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "fermented milk product does not consist of ___ ?",
        "references": [
          {
            "output": "syntax",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "milk",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id483"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "syntax",
        "answer is B.": "milk"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: fermented milk product does not consist of ___ ?\nA. syntax\nB. milk\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.7728818943724036,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.049713168293237686,
                "top_logprobs": {
                  " The answer is": -0.049713168293237686
                }
              },
              {
                "text": " B.",
                "logprob": -0.6812645792961121,
                "top_logprobs": {
                  " B.": -0.6812645792961121
                }
              },
              {
                "text": "",
                "logprob": -0.0355367511510849,
                "top_logprobs": {
                  "\n": -0.0355367511510849
                }
              },
              {
                "text": "",
                "logprob": -0.006367395631968975,
                "top_logprobs": {
                  "\n": -0.006367395631968975
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.4150390625,
        "request_datetime": 1672432890
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Quartz crystals aren't made up of",
        "references": [
          {
            "output": "hexagons",
            "tags": []
          },
          {
            "output": "majic",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id752"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "hexagons",
        "answer is B.": "majic"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Quartz crystals aren't made up of\nA. hexagons\nB. majic\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.8443929760251194,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.016350455582141876,
                "top_logprobs": {
                  " The answer is": -0.016350455582141876
                }
              },
              {
                "text": " B.",
                "logprob": -0.7880454063415527,
                "top_logprobs": {
                  " B.": -0.7880454063415527
                }
              },
              {
                "text": "",
                "logprob": -0.03696105629205704,
                "top_logprobs": {
                  "\n": -0.03696105629205704
                }
              },
              {
                "text": "",
                "logprob": -0.003036057809367776,
                "top_logprobs": {
                  "\n": -0.003036057809367776
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.32271814346313477,
        "request_datetime": 1672432890
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "nickel silver does not consist of ___ ?",
        "references": [
          {
            "output": "shrine",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "copper",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id737"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "shrine",
        "answer is B.": "copper"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: nickel silver does not consist of ___ ?\nA. shrine\nB. copper\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is A.",
            "logprob": -1.1117240246385336,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.0670834332704544,
                "top_logprobs": {
                  " The answer is": -0.0670834332704544
                }
              },
              {
                "text": " A.",
                "logprob": -0.9762330651283264,
                "top_logprobs": {
                  " A.": -0.9762330651283264
                }
              },
              {
                "text": "",
                "logprob": -0.060086268931627274,
                "top_logprobs": {
                  "\n": -0.060086268931627274
                }
              },
              {
                "text": "",
                "logprob": -0.008321257308125496,
                "top_logprobs": {
                  "\n": -0.008321257308125496
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3101222515106201,
        "request_datetime": 1672432890
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Rats cannot ___?",
        "references": [
          {
            "output": "sadness",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "bite",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id60"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "sadness",
        "answer is B.": "bite"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Rats cannot ___?\nA. sadness\nB. bite\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.674889360088855,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04629109799861908,
                "top_logprobs": {
                  " The answer is": -0.04629109799861908
                }
              },
              {
                "text": " B.",
                "logprob": -0.5966522097587585,
                "top_logprobs": {
                  " B.": -0.5966522097587585
                }
              },
              {
                "text": "",
                "logprob": -0.025523103773593903,
                "top_logprobs": {
                  "\n": -0.025523103773593903
                }
              },
              {
                "text": "",
                "logprob": -0.006422948557883501,
                "top_logprobs": {
                  "\n": -0.006422948557883501
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3493692874908447,
        "request_datetime": 1672432890
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "A landslide is not likely to occur on a slope as",
        "references": [
          {
            "output": "downward movement is facilitated",
            "tags": []
          },
          {
            "output": "there is more debris",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id810"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "downward movement is facilitated",
        "answer is B.": "there is more debris"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: A landslide is not likely to occur on a slope as\nA. downward movement is facilitated\nB. there is more debris\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.702675614040345,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.020759563893079758,
                "top_logprobs": {
                  " The answer is": -0.020759563893079758
                }
              },
              {
                "text": " B.",
                "logprob": -0.6447572112083435,
                "top_logprobs": {
                  " B.": -0.6447572112083435
                }
              },
              {
                "text": "",
                "logprob": -0.03335733711719513,
                "top_logprobs": {
                  "\n": -0.03335733711719513
                }
              },
              {
                "text": "",
                "logprob": -0.0038015018217265606,
                "top_logprobs": {
                  "\n": -0.0038015018217265606
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3259594440460205,
        "request_datetime": 1672432891
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Tire is not ___ wheels?",
        "references": [
          {
            "output": "rubber",
            "tags": []
          },
          {
            "output": "culminated",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id142"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "rubber",
        "answer is B.": "culminated"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Tire is not ___ wheels?\nA. rubber\nB. culminated\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.83420834178105,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04349001869559288,
                "top_logprobs": {
                  " The answer is": -0.04349001869559288
                }
              },
              {
                "text": " B.",
                "logprob": -0.7572265267372131,
                "top_logprobs": {
                  " B.": -0.7572265267372131
                }
              },
              {
                "text": "",
                "logprob": -0.028341056779026985,
                "top_logprobs": {
                  "\n": -0.028341056779026985
                }
              },
              {
                "text": "",
                "logprob": -0.005150739569216967,
                "top_logprobs": {
                  "\n": -0.005150739569216967
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3371284008026123,
        "request_datetime": 1672432891
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "A person wanting to find a live bear in a forest will have difficulty not because bears",
        "references": [
          {
            "output": "are friendly",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "avoid humanity",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id919"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "are friendly",
        "answer is B.": "avoid humanity"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: A person wanting to find a live bear in a forest will have difficulty not because bears\nA. are friendly\nB. avoid humanity\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.7896787626668811,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.014647684060037136,
                "top_logprobs": {
                  " The answer is": -0.014647684060037136
                }
              },
              {
                "text": " B.",
                "logprob": -0.7315885424613953,
                "top_logprobs": {
                  " B.": -0.7315885424613953
                }
              },
              {
                "text": "",
                "logprob": -0.040499065071344376,
                "top_logprobs": {
                  "\n": -0.040499065071344376
                }
              },
              {
                "text": "",
                "logprob": -0.002943471074104309,
                "top_logprobs": {
                  "\n": -0.002943471074104309
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.34121060371398926,
        "request_datetime": 1672432891
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Corn and wheat aren't among the favorite foods of",
        "references": [
          {
            "output": "humans",
            "tags": []
          },
          {
            "output": "fish",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id812"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "humans",
        "answer is B.": "fish"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Corn and wheat aren't among the favorite foods of\nA. humans\nB. fish\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.5649778109509498,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.013130507431924343,
                "top_logprobs": {
                  " The answer is": -0.013130507431924343
                }
              },
              {
                "text": " B.",
                "logprob": -0.515720546245575,
                "top_logprobs": {
                  " B.": -0.515720546245575
                }
              },
              {
                "text": "",
                "logprob": -0.03261684626340866,
                "top_logprobs": {
                  "\n": -0.03261684626340866
                }
              },
              {
                "text": "",
                "logprob": -0.003509911010041833,
                "top_logprobs": {
                  "\n": -0.003509911010041833
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3370225429534912,
        "request_datetime": 1672432891
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Percussion instruments is not made of ___?",
        "references": [
          {
            "output": "wood",
            "tags": []
          },
          {
            "output": "temple",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id122"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "wood",
        "answer is B.": "temple"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Percussion instruments is not made of ___?\nA. wood\nB. temple\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9644424361176789,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.0719776600599289,
                "top_logprobs": {
                  " The answer is": -0.0719776600599289
                }
              },
              {
                "text": " B.",
                "logprob": -0.8508715629577637,
                "top_logprobs": {
                  " B.": -0.8508715629577637
                }
              },
              {
                "text": "",
                "logprob": -0.035092685371637344,
                "top_logprobs": {
                  "\n": -0.035092685371637344
                }
              },
              {
                "text": "",
                "logprob": -0.00650052772834897,
                "top_logprobs": {
                  "\n": -0.00650052772834897
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3203003406524658,
        "request_datetime": 1672432891
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Chevrolet Trax is not produced by ___ ?",
        "references": [
          {
            "output": "specialist",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "chevrolet",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id608"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "specialist",
        "answer is B.": "chevrolet"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Chevrolet Trax is not produced by ___ ?\nA. specialist\nB. chevrolet\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9672078667208552,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.04302138090133667,
                "top_logprobs": {
                  " The answer is": -0.04302138090133667
                }
              },
              {
                "text": " B.",
                "logprob": -0.8793250322341919,
                "top_logprobs": {
                  " B.": -0.8793250322341919
                }
              },
              {
                "text": "",
                "logprob": -0.036812733858823776,
                "top_logprobs": {
                  "\n": -0.036812733858823776
                }
              },
              {
                "text": "",
                "logprob": -0.008048719726502895,
                "top_logprobs": {
                  "\n": -0.008048719726502895
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.46857333183288574,
        "request_datetime": 1672432891
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "The original language of The Bitch is not ___ ?",
        "references": [
          {
            "output": "english",
            "tags": []
          },
          {
            "output": "breton",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id416"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "english",
        "answer is B.": "breton"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: The original language of The Bitch is not ___ ?\nA. english\nB. breton\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9270787951536477,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.07062561064958572,
                "top_logprobs": {
                  " The answer is": -0.07062561064958572
                }
              },
              {
                "text": " B.",
                "logprob": -0.7860317826271057,
                "top_logprobs": {
                  " B.": -0.7860317826271057
                }
              },
              {
                "text": "",
                "logprob": -0.06332827359437943,
                "top_logprobs": {
                  "\n": -0.06332827359437943
                }
              },
              {
                "text": "",
                "logprob": -0.007093128282576799,
                "top_logprobs": {
                  "\n": -0.007093128282576799
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3764336109161377,
        "request_datetime": 1672432891
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Bill Gates does not work for ___ ?",
        "references": [
          {
            "output": "microsoft",
            "tags": []
          },
          {
            "output": "ibm",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id310"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "microsoft",
        "answer is B.": "ibm"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Bill Gates does not work for ___ ?\nA. microsoft\nB. ibm\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.8945935657247901,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.06674382090568542,
                "top_logprobs": {
                  " The answer is": -0.06674382090568542
                }
              },
              {
                "text": " B.",
                "logprob": -0.7684087753295898,
                "top_logprobs": {
                  " B.": -0.7684087753295898
                }
              },
              {
                "text": "",
                "logprob": -0.05119242146611214,
                "top_logprobs": {
                  "\n": -0.05119242146611214
                }
              },
              {
                "text": "",
                "logprob": -0.008248548023402691,
                "top_logprobs": {
                  "\n": -0.008248548023402691
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3978312015533447,
        "request_datetime": 1672432892
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Rajesh Khanna not used to communicate in ___ ?",
        "references": [
          {
            "output": "hindi",
            "tags": []
          },
          {
            "output": "yiddish",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id465"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "hindi",
        "answer is B.": "yiddish"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Rajesh Khanna not used to communicate in ___ ?\nA. hindi\nB. yiddish\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.8913723384030163,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.0822303518652916,
                "top_logprobs": {
                  " The answer is": -0.0822303518652916
                }
              },
              {
                "text": " B.",
                "logprob": -0.7622483968734741,
                "top_logprobs": {
                  " B.": -0.7622483968734741
                }
              },
              {
                "text": "",
                "logprob": -0.04161323234438896,
                "top_logprobs": {
                  "\n": -0.04161323234438896
                }
              },
              {
                "text": "",
                "logprob": -0.0052803573198616505,
                "top_logprobs": {
                  "\n": -0.0052803573198616505
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3354942798614502,
        "request_datetime": 1672432892
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Edinburgh Airport is not named after ___ ?",
        "references": [
          {
            "output": "edinburgh",
            "tags": []
          },
          {
            "output": "bourne",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id352"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "edinburgh",
        "answer is B.": "bourne"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Edinburgh Airport is not named after ___ ?\nA. edinburgh\nB. bourne\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9010263462550938,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.05994986742734909,
                "top_logprobs": {
                  " The answer is": -0.05994986742734909
                }
              },
              {
                "text": " B.",
                "logprob": -0.7960809469223022,
                "top_logprobs": {
                  " B.": -0.7960809469223022
                }
              },
              {
                "text": "",
                "logprob": -0.03766309469938278,
                "top_logprobs": {
                  "\n": -0.03766309469938278
                }
              },
              {
                "text": "",
                "logprob": -0.007332437206059694,
                "top_logprobs": {
                  "\n": -0.007332437206059694
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.32198023796081543,
        "request_datetime": 1672432892
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "William of Hirsau has not the position of ___ ?",
        "references": [
          {
            "output": "abbot",
            "tags": []
          },
          {
            "output": "republic",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id549"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "abbot",
        "answer is B.": "republic"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: William of Hirsau has not the position of ___ ?\nA. abbot\nB. republic\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.0179475843906403,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.042548637837171555,
                "top_logprobs": {
                  " The answer is": -0.042548637837171555
                }
              },
              {
                "text": " B.",
                "logprob": -0.9177253842353821,
                "top_logprobs": {
                  " B.": -0.9177253842353821
                }
              },
              {
                "text": "",
                "logprob": -0.04861900955438614,
                "top_logprobs": {
                  "\n": -0.04861900955438614
                }
              },
              {
                "text": "",
                "logprob": -0.009054552763700485,
                "top_logprobs": {
                  "\n": -0.009054552763700485
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.31832027435302734,
        "request_datetime": 1672432892
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Austrian Football Association is not a member of ___ ?",
        "references": [
          {
            "output": "lecturer",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "fifa",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id708"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "lecturer",
        "answer is B.": "fifa"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Austrian Football Association is not a member of ___ ?\nA. lecturer\nB. fifa\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.0816690810024738,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.0447741337120533,
                "top_logprobs": {
                  " The answer is": -0.0447741337120533
                }
              },
              {
                "text": " B.",
                "logprob": -0.9885578155517578,
                "top_logprobs": {
                  " B.": -0.9885578155517578
                }
              },
              {
                "text": "",
                "logprob": -0.04023389890789986,
                "top_logprobs": {
                  "\n": -0.04023389890789986
                }
              },
              {
                "text": "",
                "logprob": -0.008103232830762863,
                "top_logprobs": {
                  "\n": -0.008103232830762863
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3227424621582031,
        "request_datetime": 1672432892
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Daniele Franceschini was not born in ___ ?",
        "references": [
          {
            "output": "telegraph",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "rome",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id654"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "telegraph",
        "answer is B.": "rome"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Daniele Franceschini was not born in ___ ?\nA. telegraph\nB. rome\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.1199887716211379,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.06800055503845215,
                "top_logprobs": {
                  " The answer is": -0.06800055503845215
                }
              },
              {
                "text": " B.",
                "logprob": -1.0052850246429443,
                "top_logprobs": {
                  " B.": -1.0052850246429443
                }
              },
              {
                "text": "",
                "logprob": -0.04052699729800224,
                "top_logprobs": {
                  "\n": -0.04052699729800224
                }
              },
              {
                "text": "",
                "logprob": -0.00617619464173913,
                "top_logprobs": {
                  "\n": -0.00617619464173913
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.33542728424072266,
        "request_datetime": 1672432892
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "The native language of Louis Barthou is not ___ ?",
        "references": [
          {
            "output": "french",
            "tags": []
          },
          {
            "output": "mortar",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id572"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "french",
        "answer is B.": "mortar"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: The native language of Louis Barthou is not ___ ?\nA. french\nB. mortar\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -1.0307475007139146,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.06605086475610733,
                "top_logprobs": {
                  " The answer is": -0.06605086475610733
                }
              },
              {
                "text": " B.",
                "logprob": -0.8925591707229614,
                "top_logprobs": {
                  " B.": -0.8925591707229614
                }
              },
              {
                "text": "",
                "logprob": -0.0649137869477272,
                "top_logprobs": {
                  "\n": -0.0649137869477272
                }
              },
              {
                "text": "",
                "logprob": -0.007223678287118673,
                "top_logprobs": {
                  "\n": -0.007223678287118673
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.33864426612854004,
        "request_datetime": 1672432892
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "A thing's position is not altered when",
        "references": [
          {
            "output": "thing feels moved emotionally",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "the thing adjusts its location",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id813"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "thing feels moved emotionally",
        "answer is B.": "the thing adjusts its location"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: A thing's position is not altered when\nA. thing feels moved emotionally\nB. the thing adjusts its location\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.6752077259588987,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.01916826143860817,
                "top_logprobs": {
                  " The answer is": -0.01916826143860817
                }
              },
              {
                "text": " B.",
                "logprob": -0.6167214512825012,
                "top_logprobs": {
                  " B.": -0.6167214512825012
                }
              },
              {
                "text": "",
                "logprob": -0.03638440743088722,
                "top_logprobs": {
                  "\n": -0.03638440743088722
                }
              },
              {
                "text": "",
                "logprob": -0.002933605806902051,
                "top_logprobs": {
                  "\n": -0.002933605806902051
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3418998718261719,
        "request_datetime": 1672432893
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Name is not proper ___?",
        "references": [
          {
            "output": "noun",
            "tags": []
          },
          {
            "output": "address",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id8"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "noun",
        "answer is B.": "address"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Name is not proper ___?\nA. noun\nB. address\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is A.",
            "logprob": -1.0001114178448915,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.056548286229372025,
                "top_logprobs": {
                  " The answer is": -0.056548286229372025
                }
              },
              {
                "text": " A.",
                "logprob": -0.8711255192756653,
                "top_logprobs": {
                  " A.": -0.8711255192756653
                }
              },
              {
                "text": "",
                "logprob": -0.060494352132081985,
                "top_logprobs": {
                  "\n": -0.060494352132081985
                }
              },
              {
                "text": "",
                "logprob": -0.011943260207772255,
                "top_logprobs": {
                  "\n": -0.011943260207772255
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3326449394226074,
        "request_datetime": 1672432893
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "Which isn't recyclable",
        "references": [
          {
            "output": "Styrofoam food container",
            "tags": [
              "correct"
            ]
          },
          {
            "output": "soda can",
            "tags": []
          }
        ],
        "split": "test",
        "id": "id771"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "Styrofoam food container",
        "answer is B.": "soda can"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: Which isn't recyclable\nA. Styrofoam food container\nB. soda can\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.6716638922225684,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.0264324601739645,
                "top_logprobs": {
                  " The answer is": -0.0264324601739645
                }
              },
              {
                "text": " B.",
                "logprob": -0.6156637668609619,
                "top_logprobs": {
                  " B.": -0.6156637668609619
                }
              },
              {
                "text": "",
                "logprob": -0.026289068162441254,
                "top_logprobs": {
                  "\n": -0.026289068162441254
                }
              },
              {
                "text": "",
                "logprob": -0.0032785970252007246,
                "top_logprobs": {
                  "\n": -0.0032785970252007246
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.3600039482116699,
        "request_datetime": 1672432893
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": "The Jazztet does not play ___ music ?",
        "references": [
          {
            "output": "jazz",
            "tags": []
          },
          {
            "output": "classical",
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id230"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "answer is A.": "jazz",
        "answer is B.": "classical"
      },
      "request": {
        "model": "ai21/j1-large",
        "embedding": false,
        "prompt": "The following are multiple choice questions (with answers) about common sense.\n\nQuestion: If a cat has a body temp that is below average, it isn't in\nA. danger\nB. safe ranges\nAnswer: The answer is B.\n\nQuestion: As the barometer reading goes lower there is not a greater chance of\nA. sunshine\nB. getting wet\nAnswer: The answer is A.\n\nQuestion: Coral is a type of living organism which cannot be identified in\nA. saltwater locations that are open\nB. any where with liquid\nAnswer: The answer is B.\n\nQuestion: The Jazztet does not play ___ music ?\nA. jazz\nB. classical\nAnswer:",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 200,
        "stop_sequences": [
          "\n\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": " The answer is B.",
            "logprob": -0.9572356883436441,
            "tokens": [
              {
                "text": " The answer is",
                "logprob": -0.03730955347418785,
                "top_logprobs": {
                  " The answer is": -0.03730955347418785
                }
              },
              {
                "text": " B.",
                "logprob": -0.8730318546295166,
                "top_logprobs": {
                  " B.": -0.8730318546295166
                }
              },
              {
                "text": "",
                "logprob": -0.03827526792883873,
                "top_logprobs": {
                  "\n": -0.03827526792883873
                }
              },
              {
                "text": "",
                "logprob": -0.00861901231110096,
                "top_logprobs": {
                  "\n": -0.00861901231110096
                }
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.6358633041381836,
        "request_datetime": 1672432893
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    }
  ]
}